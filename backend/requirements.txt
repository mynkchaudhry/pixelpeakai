# File: backend/main.py
# PixelPeak Backend - Main FastAPI Application with All API Integrations

from fastapi import FastAPI, HTTPException, BackgroundTasks, File, UploadFile
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from fastapi.responses import JSONResponse, FileResponse
from pydantic import BaseModel, Field
from typing import List, Optional, Dict, Any
import os
import json
import asyncio
import logging
from datetime import datetime
import uuid

# Import our clients
from backend.clients.groq_client import GroqClient
from backend.clients.elevenlabs_client import ElevenLabsClient
from backend.clients.pinecone_client import PineconeClient
from backend.clients.readyplayerme_client import ReadyPlayerMeClient
from backend.config import config

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Initialize FastAPI app
app = FastAPI(
    title="PixelPeak BCI API",
    description="Brain-Computer Interface to VR Avatar System with Groq, ElevenLabs, Pinecone & Ready Player Me",
    version="1.0.0",
    docs_url="/docs",
    redoc_url="/redoc"
)

# CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=config.CORS_ORIGINS,
    allow_credentials=True,
    allow_methods=config.CORS_METHODS,
    allow_headers=config.CORS_HEADERS,
)

# Mount static files for audio and avatars
os.makedirs(config.AUDIO_STORAGE_PATH, exist_ok=True)
os.makedirs(config.AVATAR_STORAGE_PATH, exist_ok=True)

app.mount("/audio", StaticFiles(directory=config.AUDIO_STORAGE_PATH), name="audio")
app.mount("/avatars", StaticFiles(directory=config.AVATAR_STORAGE_PATH), name="avatars")

# =============================================================================
# PYDANTIC MODELS
# =============================================================================

class EEGScenario(BaseModel):
    """EEG scenario data model"""
    id: str = Field(..., description="Unique scenario identifier")
    emotion: str = Field(..., description="Detected emotion")
    direction: str = Field(..., description="Movement direction")
    emotion_confidence: float = Field(..., ge=0.0, le=1.0, description="Emotion confidence")
    direction_confidence: float = Field(..., ge=0.0, le=1.0, description="Direction confidence")
    speech: str = Field(..., description="Generated speech text")
    context: str = Field("", description="Additional context")
    audio_url: Optional[str] = Field(None, description="Generated audio URL")
    generated_at: str = Field(..., description="Generation timestamp")

class GenerateScenarioRequest(BaseModel):
    """Request model for generating scenarios"""
    context: Optional[str] = Field(None, description="Optional context for generation")
    emotion_hint: Optional[str] = Field(None, description="Emotion hint")
    direction_hint: Optional[str] = Field(None, description="Direction hint")

class ProcessSpeechRequest(BaseModel):
    """Request model for processing speech"""
    scenario_id: str = Field(..., description="Scenario ID to process")
    text: Optional[str] = Field(None, description="Override text")
    emotion: Optional[str] = Field(None, description="Override emotion")
    voice_id: Optional[str] = Field(None, description="Specific voice ID")

class AvatarRequest(BaseModel):
    """Request model for avatar operations"""
    avatar_type: str = Field("therapy_assistant", description="Avatar preset type")
    customizations: Optional[Dict[str, Any]] = Field(None, description="Avatar customizations")

class SimilarPatternsRequest(BaseModel):
    """Request model for finding similar EEG patterns"""
    emotion: str = Field(..., description="Current emotion")
    direction: str = Field(..., description="Current direction")
    context: str = Field("", description="Current context")
    top_k: int = Field(5, ge=1, le=20, description="Number of results")
    min_score: float = Field(0.7, ge=0.0, le=1.0, description="Minimum similarity score")

# =============================================================================
# GLOBAL CLIENTS
# =============================================================================

groq_client = None
elevenlabs_client = None
pinecone_client = None
readyplayerme_client = None

@app.on_event("startup")
async def startup_event():
    """Initialize all clients on startup"""
    global groq_client, elevenlabs_client, pinecone_client, readyplayerme_client
    
    logger.info("🚀 Starting PixelPeak BCI API...")
    
    try:
        # Initialize all clients
        groq_client = GroqClient()
        elevenlabs_client = ElevenLabsClient()
        pinecone_client = PineconeClient()
        readyplayerme_client = ReadyPlayerMeClient()
        
        # Initialize Pinecone index
        await pinecone_client.initialize()
        
        # Populate sample data if needed
        stats = await pinecone_client.get_index_stats()
        if stats.get("total_vector_count", 0) < 5:
            logger.info("📊 Populating sample EEG patterns...")
            await pinecone_client.populate_sample_data(20)
        
        logger.info("🎉 All services initialized successfully!")
        
    except Exception as e:
        logger.error(f"❌ Failed to initialize services: {str(e)}")
        raise

@app.on_event("shutdown")
async def shutdown_event():
    """Cleanup on shutdown"""
    logger.info("🛑 Shutting down PixelPeak BCI API...")
    if pinecone_client:
        await pinecone_client.close()

# =============================================================================
# HEALTH CHECK ENDPOINTS
# =============================================================================

@app.get("/")
async def root():
    """Root endpoint with API information"""
    return {
        "message": "PixelPeak BCI API",
        "version": "1.0.0",
        "status": "running",
        "services": ["Groq LLM", "ElevenLabs TTS", "Pinecone Vector DB", "Ready Player Me"],
        "docs": "/docs",
        "endpoints": {
            "scenarios": "/api/scenarios",
            "generate": "/api/generate-scenario",
            "speech": "/api/process-speech",
            "avatars": "/api/avatars",
            "similar": "/api/similar-patterns"
        }
    }

@app.get("/api/health")
async def health_check():
    """Comprehensive health check for all services"""
    try:
        # Test all services
        services_status = {}
        
        if groq_client:
            services_status["groq"] = await groq_client.health_check()
        
        if elevenlabs_client:
            services_status["elevenlabs"] = await elevenlabs_client.health_check()
        
        if pinecone_client:
            services_status["pinecone"] = await pinecone_client.health_check()
        
        if readyplayerme_client:
            services_status["ready_player_me"] = await readyplayerme_client.health_check()
        
        # Get API key validation
        api_keys = config.validate_api_keys()
        
        all_healthy = all(services_status.values())
        
        return {
            "status": "healthy" if all_healthy else "degraded",
            "timestamp": datetime.now().isoformat(),
            "services": {k: "✅" if v else "❌" for k, v in services_status.items()},
            "api_keys": {k: "✅" if v else "❌" for k, v in api_keys.items()},
            "uptime": "operational"
        }
        
    except Exception as e:
        return JSONResponse(
            status_code=500,
            content={
                "status": "unhealthy",
                "error": str(e),
                "timestamp": datetime.now().isoformat()
            }
        )

# =============================================================================
# SCENARIO ENDPOINTS
# =============================================================================

@app.get("/api/scenarios", response_model=List[EEGScenario])
async def get_scenarios():
    """Get list of recent EEG scenarios"""
    try:
        # For demo, return some mock scenarios
        # In production, this would fetch from database
        mock_scenarios = [
            EEGScenario(
                id="demo_1",
                emotion="calm",
                direction="forward",
                emotion_confidence=0.87,
                direction_confidence=0.92,
                speech="I feel peaceful and ready to move forward",
                context="Patient in relaxed state",
                generated_at=datetime.now().isoformat()
            ),
            EEGScenario(
                id="demo_2", 
                emotion="excited",
                direction="left",
                emotion_confidence=0.94,
                direction_confidence=0.78,
                speech="I'm energized! Let's turn left and explore",
                context="High energy state",
                generated_at=datetime.now().isoformat()
            ),
            EEGScenario(
                id="demo_3",
                emotion="sad",
                direction="stop",
                emotion_confidence=0.76,
                direction_confidence=0.85,
                speech="I'm feeling down right now, I need to pause",
                context="Low mood, needs support",
                generated_at=datetime.now().isoformat()
            )
        ]
        
        return mock_scenarios
        
    except Exception as e:
        logger.error(f"Error getting scenarios: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/generate-scenario", response_model=EEGScenario)
async def generate_scenario(request: GenerateScenarioRequest):
    """Generate new EEG scenario using Groq LLM"""
    try:
        # Generate scenario using Groq
        scenario_data = await groq_client.generate_eeg_scenario(request.context)
        
        # Store pattern in Pinecone for similarity search
        confidence_scores = {
            "emotion": scenario_data["emotion_confidence"],
            "direction": scenario_data["direction_confidence"]
        }
        
        await pinecone_client.store_eeg_pattern(
            pattern_id=scenario_data["id"],
            emotion=scenario_data["emotion"],
            direction=scenario_data["direction"],
            context=scenario_data.get("context", ""),
            confidence_scores=confidence_scores,
            metadata={"source": "groq_generated", "session": "api"}
        )
        
        # Convert to response model
        scenario = EEGScenario(
            id=scenario_data["id"],
            emotion=scenario_data["emotion"],
            direction=scenario_data["direction"],
            emotion_confidence=scenario_data["emotion_confidence"],
            direction_confidence=scenario_data["direction_confidence"],
            speech=scenario_data["speech"],
            context=scenario_data.get("context", ""),
            generated_at=scenario_data["generated_at"]
        )
        
        logger.info(f"✅ Generated scenario: {scenario.emotion} + {scenario.direction}")
        return scenario
        
    except Exception as e:
        logger.error(f"Error generating scenario: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Failed to generate scenario: {str(e)}")

@app.post("/api/process-speech")
async def process_speech(request: ProcessSpeechRequest):
    """Convert scenario text to speech using ElevenLabs"""
    try:
        # Get scenario details (in production, fetch from database)
        text = request.text or "I want to communicate through my thoughts"
        emotion = request.emotion or "calm"
        
        # Generate speech using ElevenLabs
        speech_result = await elevenlabs_client.text_to_speech(
            text=text,
            emotion=emotion,
            voice_id=request.voice_id
        )
        
        if speech_result["success"]:
            return {
                "success": True,
                "scenario_id": request.scenario_id,
                "text": text,
                "emotion": emotion,
                "audio_url": speech_result["url"],
                "filename": speech_result["filename"],
                "duration_estimate": speech_result["duration_estimate"],
                "voice_id": speech_result["voice_id"],
                "generated_at": speech_result["generated_at"]
            }
        else:
            return {
                "success": False,
                "error": speech_result.get("error", "TTS generation failed"),
                "fallback_url": speech_result.get("url")
            }
        
    except Exception as e:
        logger.error(f"Error processing speech: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Failed to process speech: {str(e)}")

# =============================================================================
# PINECONE SIMILARITY ENDPOINTS
# =============================================================================

@app.post("/api/similar-patterns")
async def find_similar_patterns(request: SimilarPatternsRequest):
    """Find similar EEG patterns using Pinecone vector search"""
    try:
        # Find similar patterns
        similar_patterns = await pinecone_client.find_similar_patterns(
            emotion=request.emotion,
            direction=request.direction,
            context=request.context,
            top_k=request.top_k,
            min_score=request.min_score
        )
        
        return {
            "success": True,
            "query": {
                "emotion": request.emotion,
                "direction": request.direction,
                "context": request.context
            },
            "similar_patterns": similar_patterns,
            "count": len(similar_patterns)
        }
        
    except Exception as e:
        logger.error(f"Error finding similar patterns: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Failed to find similar patterns: {str(e)}")

@app.get("/api/patterns/stats")
async def get_pattern_stats():
    """Get Pinecone index statistics"""
    try:
        stats = await pinecone_client.get_index_stats()
        return {
            "success": True,
            "stats": stats,
            "index_name": config.PINECONE_INDEX_NAME,
            "dimension": config.PINECONE_DIMENSION
        }
    except Exception as e:
        logger.error(f"Error getting pattern stats: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

# =============================================================================
# AVATAR ENDPOINTS (Ready Player Me)
# =============================================================================

@app.post("/api/avatars/create-preset")
async def create_preset_avatar(request: AvatarRequest):
    """Create avatar from preset using Ready Player Me"""
    try:
        avatar_result = await readyplayerme_client.create_preset_avatar(
            preset_type=request.avatar_type,
            customizations=request.customizations
        )
        
        return avatar_result
        
    except Exception as e:
        logger.error(f"Error creating avatar: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Failed to create avatar: {str(e)}")

@app.post("/api/avatars/create-from-photo")
async def create_avatar_from_photo(
    photo: UploadFile = File(...),
    gender: str = "female",
    style: str = "realistic"
):
    """Create avatar from uploaded photo"""
    try:
        # Read photo data
        photo_data = await photo.read()
        
        # Create avatar
        avatar_result = await readyplayerme_client.create_avatar_from_photo(
            photo_data=photo_data,
            gender=gender,
            style=style
        )
        
        return avatar_result
        
    except Exception as e:
        logger.error(f"Error creating avatar from photo: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Failed to create avatar: {str(e)}")

@app.get("/api/avatars")
async def list_avatars():
    """List all user avatars"""
    try:
        avatars = await readyplayerme_client.list_user_avatars()
        return {
            "success": True,
            "avatars": avatars,
            "count": len(avatars)
        }
    except Exception as e:
        logger.error(f"Error listing avatars: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/avatars/{avatar_id}")
async def get_avatar_info(avatar_id: str):
    """Get avatar information"""
    try:
        avatar_info = await readyplayerme_client.get_avatar_info(avatar_id)
        if avatar_info:
            return {"success": True, "avatar": avatar_info}
        else:
            raise HTTPException(status_code=404, detail="Avatar not found")
    except Exception as e:
        logger.error(f"Error getting avatar info: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/avatars/{avatar_id}/animations")
async def get_avatar_animations(avatar_id: str):
    """Get available animations for avatar"""
    try:
        animations = await readyplayerme_client.get_avatar_animations(avatar_id)
        return {
            "success": True,
            "avatar_id": avatar_id,
            "animations": animations,
            "count": len(animations)
        }
    except Exception as e:
        logger.error(f"Error getting avatar animations: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@app.delete("/api/avatars/{avatar_id}")
async def delete_avatar(avatar_id: str):
    """Delete avatar"""
    try:
        success = await readyplayerme_client.delete_avatar(avatar_id)
        if success:
            return {"success": True, "message": f"Avatar {avatar_id} deleted"}
        else:
            raise HTTPException(status_code=400, detail="Failed to delete avatar")
    except Exception as e:
        logger.error(f"Error deleting avatar: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

# =============================================================================
# AUDIO FILE SERVING
# =============================================================================

@app.get("/api/audio/{filename}")
async def serve_audio(filename: str):
    """Serve audio files"""
    try:
        file_path = os.path.join(config.AUDIO_STORAGE_PATH, filename)
        if os.path.exists(file_path):
            return FileResponse(
                file_path,
                media_type="audio/mpeg",
                headers={"Content-Disposition": f"inline; filename={filename}"}
            )
        else:
            raise HTTPException(status_code=404, detail="Audio file not found")
    except Exception as e:
        logger.error(f"Error serving audio: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

# =============================================================================
# COMBINED WORKFLOW ENDPOINTS
# =============================================================================

@app.post("/api/complete-workflow")
async def complete_workflow(request: GenerateScenarioRequest):
    """Complete BCI workflow: Generate scenario → Create speech → Store pattern"""
    try:
        # Step 1: Generate scenario with Groq
        scenario_data = await groq_client.generate_eeg_scenario(request.context)
        
        # Step 2: Generate speech with ElevenLabs
        speech_result = await elevenlabs_client.text_to_speech(
            text=scenario_data["speech"],
            emotion=scenario_data["emotion"]
        )
        
        # Step 3: Store pattern in Pinecone
        confidence_scores = {
            "emotion": scenario_data["emotion_confidence"],
            "direction": scenario_data["direction_confidence"]
        }
        
        await pinecone_client.store_eeg_pattern(
            pattern_id=scenario_data["id"],
            emotion=scenario_data["emotion"],
            direction=scenario_data["direction"],
            context=scenario_data.get("context", ""),
            confidence_scores=confidence_scores,
            metadata={"source": "complete_workflow", "has_audio": speech_result["success"]}
        )
        
        # Step 4: Return complete result
        return {
            "success": True,
            "scenario": {
                "id": scenario_data["id"],
                "emotion": scenario_data["emotion"],
                "direction": scenario_data["direction"],
                "emotion_confidence": scenario_data["emotion_confidence"],
                "direction_confidence": scenario_data["direction_confidence"],
                "speech": scenario_data["speech"],
                "context": scenario_data.get("context", ""),
                "generated_at": scenario_data["generated_at"]
            },
            "audio": {
                "url": speech_result["url"] if speech_result["success"] else None,
                "filename": speech_result.get("filename"),
                "success": speech_result["success"]
            },
            "stored_in_pinecone": True
        }
        
    except Exception as e:
        logger.error(f"Error in complete workflow: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Workflow failed: {str(e)}")

@app.post("/api/process-eeg-data")
async def process_eeg_data(
    emotion: str,
    direction: str,
    context: str = "",
    emotion_confidence: float = 0.8,
    direction_confidence: float = 0.8
):
    """Process EEG data: Find similar patterns → Generate speech → Store new pattern"""
    try:
        # Step 1: Find similar patterns in Pinecone
        similar_patterns = await pinecone_client.find_similar_patterns(
            emotion=emotion,
            direction=direction,
            context=context,
            top_k=3,
            min_score=0.7
        )
        
        # Step 2: Generate natural speech with Groq
        speech_text = await groq_client.emotion_to_speech(
            emotion=emotion,
            direction=direction,
            emotion_confidence=emotion_confidence,
            direction_confidence=direction_confidence,
            context=context
        )
        
        # Step 3: Convert to audio with ElevenLabs
        audio_result = await elevenlabs_client.text_to_speech(
            text=speech_text,
            emotion=emotion
        )
        
        # Step 4: Store new pattern
        pattern_id = f"processed_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{uuid.uuid4().hex[:8]}"
        
        await pinecone_client.store_eeg_pattern(
            pattern_id=pattern_id,
            emotion=emotion,
            direction=direction,
            context=context,
            confidence_scores={"emotion": emotion_confidence, "direction": direction_confidence},
            metadata={"source": "eeg_processing", "processed_at": datetime.now().isoformat()}
        )
        
        return {
            "success": True,
            "processed_data": {
                "pattern_id": pattern_id,
                "emotion": emotion,
                "direction": direction,
                "emotion_confidence": emotion_confidence,
                "direction_confidence": direction_confidence,
                "generated_speech": speech_text,
                "audio_url": audio_result["url"] if audio_result["success"] else None
            },
            "similar_patterns": similar_patterns,
            "similar_count": len(similar_patterns)
        }
        
    except Exception as e:
        logger.error(f"Error processing EEG data: {str(e)}")
        raise HTTPException(status_code=500, detail=f"EEG processing failed: {str(e)}")

# =============================================================================
# UTILITY ENDPOINTS
# =============================================================================

@app.get("/api/voices")
async def get_available_voices():
    """Get available ElevenLabs voices"""
    try:
        voices = await elevenlabs_client.get_available_voices()
        return {
            "success": True,
            "voices": voices,
            "count": len(voices)
        }
    except Exception as e:
        logger.error(f"Error getting voices: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/config")
async def get_api_config():
    """Get API configuration info"""
    try:
        api_keys = config.validate_api_keys()
        return {
            "services": {
                "groq_model": config.GROQ_MODEL,
                "pinecone_index": config.PINECONE_INDEX_NAME,
                "elevenlabs_voice": config.ELEVENLABS_VOICE_ID,
                "ready_player_me_subdomain": config.READY_PLAYER_ME_SUBDOMAIN
            },
            "api_keys_valid": api_keys,
            "storage_paths": {
                "audio": config.AUDIO_STORAGE_PATH,
                "avatars": config.AVATAR_STORAGE_PATH
            }
        }
    except Exception as e:
        logger.error(f"Error getting config: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

# =============================================================================
# ERROR HANDLERS
# =============================================================================

@app.exception_handler(HTTPException)
async def http_exception_handler(request, exc):
    """Custom HTTP exception handler"""
    return JSONResponse(
        status_code=exc.status_code,
        content={
            "error": exc.detail,
            "status_code": exc.status_code,
            "timestamp": datetime.now().isoformat(),
            "path": str(request.url)
        }
    )

@app.exception_handler(Exception)
async def general_exception_handler(request, exc):
    """General exception handler"""
    logger.error(f"Unhandled exception: {str(exc)}")
    return JSONResponse(
        status_code=500,
        content={
            "error": "Internal server error",
            "message": str(exc),
            "timestamp": datetime.now().isoformat(),
            "path": str(request.url)
        }
    )

# =============================================================================
# MAIN APPLICATION
# =============================================================================

if __name__ == "__main__":
    import uvicorn
    
    print("🚀 Starting PixelPeak BCI API Server...")
    print(f"📍 Docs available at: http://localhost:{config.PORT}/docs")
    print(f"🎵 Audio files at: http://localhost:{config.PORT}/audio/")
    print(f"👤 Avatar files at: http://localhost:{config.PORT}/avatars/")
    
    uvicorn.run(
        "main:app",
        host=config.HOST,
        port=config.PORT,
        reload=config.RELOAD,
        log_level="info"
    )